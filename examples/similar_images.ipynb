{
 "metadata": {
  "name": "",
  "signature": "sha256:2b0e670011c38329b698a1bc3089a5206078e5a0dc88403ba7a6bc065fca474d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Predicting Similar Images\n",
      "========================="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, we will retrieve the five most similar images to a given image.\n",
      "\n",
      "Searching for similar images is commonly required for product recommendations or image search and sometimes in fraud detection etc.\n",
      "\n",
      "Images are converted to a hash or an embedding that preserves the semantic properties of the image. When a new image arrives, its embedding is generated and the search proceeds using this embedding.\n",
      "\n",
      "Here, we will use a publicly available (for non-commercial use) pre-trained model - [Deep Learning of Binary Hash Codes for Fast Image Retrieval](https://github.com/kevinlin311tw/caffe-cvprw15) - to generate the embeddings.\n",
      "\n",
      "This model has been trained on images in the [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. This dataset has images in 10 categories (airplane, bird, etc...).\n",
      "\n",
      "If you ran the setup steps in [Getting Started](http://flipkart-incubator.github.io/Cuppa/getting-started.html), then the pre-trained model is already downloaded and ready to use.\n",
      "\n",
      "We will use this model to generate embeddings for the images in [examples/img_urls.tsv](https://github.com/flipkart-incubator/Cuppa/blob/master/examples/img_urls.tsv).\n",
      "\n",
      "\n",
      "If the caffe service, knn service and the router are up, then the steps we need to run are -\n",
      "1. Load this model in the caffe service\n",
      "2. Register the caffe and knn service to the router\n",
      "3. Use the caffe service 'predict api' to generate embeddings for images in [examples/img_urls.tsv](https://github.com/flipkart-incubator/Cuppa/blob/master/examples/img_urls.tsv).\n",
      "4. Insert the generated embeddings into the knn service using the 'insert api'.\n",
      "5. Pick an image for which we want to find similar images. \n",
      "6. Use the caffe service 'predict api' to generate the embedding for this image.\n",
      "7. Predict the nearest neighbours for this image using the knn 'predict api'.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1. Load the model and update the router with caffe service and knn service endpoint details"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "#Tell the Caas service to load the model.\n",
      "fab -f caas/worker/worker_client.py commission:config_path=conf/caas_config.yaml,worker_id=0,model_id=KevinNet_CIFAR10_48\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2. Register the caffe and knn service to the router"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "#Register the Caas and Knnaas service with the router.\n",
      "curl -H \"Content-Type: application/json\" -X PUT -d '{\"Caffe\": {\"KevinNet_CIFAR10_48\": [{\"host\": \"localhost\",\"port\": 9091,\"local_worker_id\": 0}]}, \"KNN\": {\"model-1\": [{\"host\":\"localhost\",\"port\":9090, \"local_worker_id\" : 0}]}}' http://localhost:8000/v1/model_workers_map\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3. Use the caffe service 'predict api' to generate embeddings for images in [examples/img_urls.tsv](https://github.com/flipkart-incubator/Cuppa/blob/master/examples/img_urls.tsv)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we do this, lets look at some of the images in our dataset. First, lets print all the image classes in the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read the image urls file\n",
      "img_urls = {}\n",
      "with open('img_urls.tsv') as imgs_tsv:\n",
      "    for line in imgs_tsv.readlines():\n",
      "        (cifar_class, url) = line.strip().split('\\t')\n",
      "        img_list = img_urls.get(cifar_class, [])\n",
      "        img_list.append(url)\n",
      "        img_urls[cifar_class] = img_list\n",
      "\n",
      "print(img_urls.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['horse', 'automobile', 'deer', 'dog', 'frog', 'cat', 'truck', 'ship', 'airplane', 'bird']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is one image from each of the image classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image, display\n",
      "\n",
      "for img_class in img_urls.keys():\n",
      "    display(Image(url=img_urls[img_class][0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/12/02374451/bd/bd35c9c05d7ccd205b34cb3d4ae4bdcae1a8a8b8.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6650>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/11/02958343/7d/7d816522144f156e806a8303178af8282adef8bc.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6bd0>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/14/02430045/8f/8f05fa73ad41203104dcbbb66a73bb2353ebd315.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6190>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/11/02084071/5f/5f094c4993438264fff75ef5833db81bd777d7a8.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6350>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/9/01639765/2d/2d5c39e1c3d296d0c2cececb3ac8f279f3cdc86b.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6290>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/6/02121620/ba/ba001acd71960b0d72c1a6305fdc5f827461af9e.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f62d0>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/1/04490091/8d/8d902e72ab1f2ffab22dc578ae2e9a760ebec50f.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6310>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/1/04194289/01/017c23253cf1a6433e842efe063064aa01b686e3.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/1/02691156/17/17af00938daad80b5e97027f6b3a3e1f1627aea2.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6190>"
       ]
      },
      {
       "html": [
        "<img src=\"http://www.image-net.org/nodes/1/01503061/04/04db22a9bc724ebf1840c6c3631d51790e0f021a.thumb\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f16b66f6bd0>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets generate the embedding for one image and see what it looks like -"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, json\n",
      "\n",
      "embedding_request = {\n",
      "                     \"url\": img_urls['horse'][0], \n",
      "                     \"modelId\": \"KevinNet_CIFAR10_48\"\n",
      "                    }\n",
      "\n",
      "response = requests.post('http://localhost:8000/v1/caffe_model/predict', \n",
      "                         data = json.dumps(embedding_request), \n",
      "                         headers = {'Content-Type': 'application/json'})\n",
      "\n",
      "print(response.status_code)\n",
      "print(response.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n",
        "[0.018448345363140106, 0.9855384826660156, 0.0005375780747272074, 0.016542669385671616, 0.0028725676238536835, 0.01883883588016033, 0.7837542295455933, 0.9421281814575195, 0.858430802822113, 0.06279351562261581, 0.019347021356225014, 0.93182772397995, 0.8539321422576904, 0.8034805655479431, 0.5766627788543701, 0.653766393661499, 0.016270926222205162, 0.9680255651473999, 0.9256700277328491, 0.9823125004768372, 0.99410480260849, 0.03165864199399948, 0.9952507615089417, 0.4026651382446289, 0.7379107475280762, 0.01387855876237154, 0.9996728301048279, 0.9999628067016602, 0.992577850818634, 0.9867085814476013, 0.21673664450645447, 0.9957020282745361, 0.0015155583387240767, 0.9227782487869263, 0.0008746151579543948, 0.9989007711410522, 0.08006580919027328, 0.0006333822384476662, 0.09225847572088242, 0.0005493158241733909, 0.0007938891067169607, 0.015284442342817783, 0.7659894824028015, 0.02385750040411949, 0.8482775092124939, 0.4759948253631592, 0.5717042088508606, 0.9377776384353638]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Insert the generated embeddings into the knn service using the 'insert api'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec = json.loads(response.content)\n",
      "\n",
      "insert_request = {\n",
      "                    \"modelId\":\"model-1\", \n",
      "                    \"operation\": \"insert\", \n",
      "                    \"dataPointId\": \"1\", \n",
      "                    \"vector\": vec, \n",
      "                    \"tags\": [\"\"]\n",
      "                }\n",
      "response = requests.post('http://localhost:8000/v1/knn_model/update', \n",
      "                         data= json.dumps(insert_request), \n",
      "                         headers={'Content-Type': 'application/json'})\n",
      "print(response.status_code)\n",
      "print(response.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n",
        "{\"status\": \"Success\"}\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Do this for all images now"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create an id to url map\n",
      "id_to_imgurl_map = {}\n",
      "i=0\n",
      "for class_imgs in img_urls.itervalues():\n",
      "    for img in class_imgs:\n",
      "        id_to_imgurl_map[i]=img\n",
      "        i+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "status_200=0\n",
      "for (img_id, imgurl) in id_to_imgurl_map.iteritems():\n",
      "    \n",
      "    img_payload = {\"url\":imgurl, \"modelId\": \"KevinNet_CIFAR10_48\"}\n",
      "    \n",
      "    response = requests.post('http://localhost:8000/v1/caffe_model/predict', \n",
      "                             data=json.dumps(img_payload), \n",
      "                             headers={'Content-Type': 'application/json'})\n",
      "    \n",
      "    vec = json.loads(response.content)\n",
      "\n",
      "    insert_payload = {\"modelId\":\"model-1\", \"operation\": \"insert\", \"dataPointId\": str(img_id), \"vector\": vec, \"tags\": [\"\"]}\n",
      "   \n",
      "    response = requests.post('http://localhost:8000/v1/knn_model/update', \n",
      "                  data= json.dumps(insert_payload), \n",
      "                  headers={'Content-Type': 'application/json'})\n",
      "    \n",
      "    #count the number of successful requests\n",
      "    if response.status_code == 200:\n",
      "        status_200+=1\n",
      "\n",
      "print(str(status_200))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If it printed 113 above, then we succesfully generated embeddings for all images and inserted them into the knn service."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##5. Pick an image for which we want to find similar images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_img = \"http://news.nationalgeographic.com/news/2007/09/images/070928-frog-picture_big.jpg\"\n",
      "display(Image(url=search_img))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://news.nationalgeographic.com/news/2007/09/images/070928-frog-picture_big.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7ff5254c2f90>"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##6. Use the caffe service 'predict api' to generate the embedding for this image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now find nearest neighbours for an image\n",
      "#Now predict\n",
      "#d3 = {\"url\":\"http://localhost:8500/1314.jpg\", \"modelId\": \"KevinNet_CIFAR10_48\"}\n",
      "#d3 = {\"url\":\"http://imagecdn8.cartrade.com/img/800x600/car-data/big/maruti-suzuki-swift-default-image.png\", \"modelId\": \"KevinNet_CIFAR10_48\"}\n",
      "#d3 = {\"url\":\"http://www.image-net.org/nodes/5/02960352/1f/1f131ee4f7d4c438f1d2e286eda6bc2ef6dbc469.thumb\", \"modelId\": \"KevinNet_CIFAR10_48\"}\n",
      "d3 = {\"url\":\"http://news.nationalgeographic.com/news/2007/09/images/070928-frog-picture_big.jpg\", \"modelId\": \"KevinNet_CIFAR10_48\"}\n",
      "\n",
      "response = requests.post('http://localhost:8000/v1/caffe_model/predict', \n",
      "                         data= json.dumps(d3), \n",
      "                         headers={'Content-Type': 'application/json'})\n",
      "print(response.status_code)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##7. Predict the nearest neighbours for this image using the knn 'predict api'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec = json.loads(response.content)\n",
      "d4 = {\"modelId\":\"model-1\", \"operation\": \"SearchByVector\", \"vector\": vec, \"tags\":[\"\"]}\n",
      "response = requests.post('http://localhost:8000/v1/knn_model/predict', \n",
      "                         data= json.dumps(d4), \n",
      "                         headers={'Content-Type': 'application/json'})\n",
      "print(response.status_code)\n",
      "predictions = json.loads(response.content)\n",
      "ids_dists = predictions[u'result']\n",
      "ids_dists.reverse()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(ids_dists)\n",
      "images = []\n",
      "for id_dist in ids_dists:\n",
      "    images.append(Image(url=id_to_imgurl_map[int(id_dist[0])]))\n",
      "print(\"Here are the nearest neighbours for our sample image\")                  \n",
      "display(images[0], images[1], images[2], images[3], images[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}